{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsFqqI3E8Xn4"
      },
      "source": [
        "## Chatbots With Langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDGN7B1e8cX_",
        "outputId": "72a6b2d2-b5c0-4b21-fa0d-2d1bb4985267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.22-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: langsmith in c:\\users\\richa\\anaconda3\\lib\\site-packages (0.1.88)\n",
            "Collecting langchain-core<0.4,>=0.2.39 (from langgraph)\n",
            "  Downloading langchain_core-0.3.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-1.0.10-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langsmith) (3.9.15)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langsmith) (1.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langsmith) (2.27.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (1.33)\n",
            "Collecting langsmith\n",
            "  Downloading langsmith-0.1.122-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (23.2)\n",
            "Collecting pydantic<3,>=1 (from langsmith)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (8.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.2.39->langgraph) (4.11.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langsmith) (0.27.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\richa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.3.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\richa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\richa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\users\\richa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.7)\n",
            "Requirement already satisfied: sniffio in c:\\users\\richa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<2.0.0,>=1.0.2->langgraph)\n",
            "  Downloading msgpack-1.1.0-cp310-cp310-win_amd64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langsmith) (0.6.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1->langsmith)\n",
            "  Downloading pydantic_core-2.23.4-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith) (1.26.19)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith) (2.0.12)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.39->langgraph) (2.4)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.1)\n",
            "Downloading langgraph-0.2.22-py3-none-any.whl (98 kB)\n",
            "Downloading langchain_core-0.3.1-py3-none-any.whl (405 kB)\n",
            "Downloading langsmith-0.1.122-py3-none-any.whl (289 kB)\n",
            "Downloading langgraph_checkpoint-1.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "Downloading pydantic_core-2.23.4-cp310-none-win_amd64.whl (1.9 MB)\n",
            "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
            "   -------------------------------------- - 1.8/1.9 MB 9.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.9/1.9 MB 8.2 MB/s eta 0:00:00\n",
            "Downloading msgpack-1.1.0-cp310-cp310-win_amd64.whl (74 kB)\n",
            "Installing collected packages: pydantic-core, msgpack, pydantic, langsmith, langchain-core, langgraph-checkpoint, langgraph\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.18.2\n",
            "    Uninstalling pydantic_core-2.18.2:\n",
            "      Successfully uninstalled pydantic_core-2.18.2\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.8\n",
            "    Uninstalling msgpack-1.0.8:\n",
            "      Successfully uninstalled msgpack-1.0.8\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.9.2\n",
            "    Uninstalling pydantic-1.9.2:\n",
            "      Successfully uninstalled pydantic-1.9.2\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.1.88\n",
            "    Uninstalling langsmith-0.1.88:\n",
            "      Successfully uninstalled langsmith-0.1.88\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.2.20\n",
            "    Uninstalling langchain-core-0.2.20:\n",
            "      Successfully uninstalled langchain-core-0.2.20\n",
            "Successfully installed langchain-core-0.3.1 langgraph-0.2.22 langgraph-checkpoint-1.0.10 langsmith-0.1.122 msgpack-1.1.0 pydantic-2.9.2 pydantic-core-2.23.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chromadb 0.4.24 requires requests>=2.28, but you have requests 2.27.1 which is incompatible.\n",
            "chromadb 0.4.24 requires tqdm>=4.65.0, but you have tqdm 4.64.1 which is incompatible.\n",
            "crewai 0.28.8 requires langchain<0.2.0,>=0.1.10, but you have langchain 0.2.0 which is incompatible.\n",
            "crewai 0.28.8 requires openai<2.0.0,>=1.13.3, but you have openai 0.10.2 which is incompatible.\n",
            "crewai-tools 0.2.3 requires beautifulsoup4<5.0.0,>=4.12.3, but you have beautifulsoup4 4.10.0 which is incompatible.\n",
            "crewai-tools 0.2.3 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.2.0 which is incompatible.\n",
            "crewai-tools 0.2.3 requires openai<2.0.0,>=1.12.0, but you have openai 0.10.2 which is incompatible.\n",
            "crewai-tools 0.2.3 requires requests<3.0.0,>=2.31.0, but you have requests 2.27.1 which is incompatible.\n",
            "embedchain 0.1.102 requires beautifulsoup4<5.0.0,>=4.12.2, but you have beautifulsoup4 4.10.0 which is incompatible.\n",
            "embedchain 0.1.102 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.2.0 which is incompatible.\n",
            "embedchain 0.1.102 requires langchain-openai<0.0.6,>=0.0.5, but you have langchain-openai 0.1.3 which is incompatible.\n",
            "embedchain 0.1.102 requires openai>=1.1.1, but you have openai 0.10.2 which is incompatible.\n",
            "embedchain 0.1.102 requires pypdf<4.0.0,>=3.11.0, but you have pypdf 4.2.0 which is incompatible.\n",
            "fastapi-utils 0.2.1 requires pydantic<2.0,>=1.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "fastapi-utils 0.2.1 requires sqlalchemy<2.0.0,>=1.3.12, but you have sqlalchemy 2.0.29 which is incompatible.\n",
            "google-cloud-aiplatform 1.50.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "gradio 4.26.0 requires python-multipart>=0.0.9, but you have python-multipart 0.0.7 which is incompatible.\n",
            "instructor 0.5.2 requires openai<2.0.0,>=1.1.0, but you have openai 0.10.2 which is incompatible.\n",
            "lancedb 0.5.7 requires requests>=2.31.0, but you have requests 2.27.1 which is incompatible.\n",
            "langchain 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.1 which is incompatible.\n",
            "langchain-anthropic 0.1.20 requires langchain-core<0.3,>=0.2.17, but you have langchain-core 0.3.1 which is incompatible.\n",
            "langchain-astradb 0.3.0 requires langchain-core<0.2.0,>=0.1.31, but you have langchain-core 0.3.1 which is incompatible.\n",
            "langchain-community 0.0.38 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.3.1 which is incompatible.\n",
            "langchain-google-genai 0.0.11 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.3.1 which is incompatible.\n",
            "langchain-google-vertexai 1.0.1 requires langchain-core<0.2.0,>=0.1.42, but you have langchain-core 0.3.1 which is incompatible.\n",
            "langchain-groq 0.1.3 requires langchain-core<0.2.0,>=0.1.45, but you have langchain-core 0.3.1 which is incompatible.\n",
            "langchain-nvidia-ai-endpoints 0.0.9 requires langchain-core<0.2.0,>=0.1.27, but you have langchain-core 0.3.1 which is incompatible.\n",
            "langchain-openai 0.1.3 requires langchain-core<0.2.0,>=0.1.42, but you have langchain-core 0.3.1 which is incompatible.\n",
            "langchain-openai 0.1.3 requires openai<2.0.0,>=1.10.0, but you have openai 0.10.2 which is incompatible.\n",
            "langchain-text-splitters 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.1 which is incompatible.\n",
            "llama-index-llms-anthropic 0.1.11 requires anthropic<0.24.0,>=0.23.1, but you have anthropic 0.31.2 which is incompatible.\n",
            "pandasai 2.0.43 requires pandas==1.5.3, but you have pandas 2.2.2 which is incompatible.\n",
            "pandasai 2.0.43 requires requests<3.0.0,>=2.31.0, but you have requests 2.27.1 which is incompatible.\n",
            "pyautogen 0.2.22 requires openai>=1.3, but you have openai 0.10.2 which is incompatible.\n",
            "qianfan 0.3.0 requires python-dotenv<=0.21.1, but you have python-dotenv 1.0.0 which is incompatible.\n",
            "radiant-mlhub 0.5.5 requires pydantic~=1.9.2, but you have pydantic 2.9.2 which is incompatible.\n",
            "ragstack-ai-colbert 1.0.2 requires torch==2.2.1, but you have torch 2.3.1+cu121 which is incompatible.\n",
            "ragstack-ai-langchain 1.0.3 requires langchain==0.1.19, but you have langchain 0.2.0 which is incompatible.\n",
            "ragstack-ai-langchain 1.0.3 requires langchain-core==0.1.52, but you have langchain-core 0.3.1 which is incompatible.\n",
            "zenml 0.50.0 requires alembic<1.9.0,>=1.8.1, but you have alembic 1.13.1 which is incompatible.\n",
            "zenml 0.50.0 requires click<8.1.4,>=8.0.1, but you have click 8.1.7 which is incompatible.\n",
            "zenml 0.50.0 requires cloudpickle<3,>=2.0.0, but you have cloudpickle 3.0.0 which is incompatible.\n",
            "zenml 0.50.0 requires docker<6.2.0,>=6.1.0, but you have docker 7.0.0 which is incompatible.\n",
            "zenml 0.50.0 requires httplib2<0.20,>=0.19.1, but you have httplib2 0.22.0 which is incompatible.\n",
            "zenml 0.50.0 requires pydantic<1.11,>=1.9.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "zenml 0.50.0 requires sqlmodel==0.0.8, but you have sqlmodel 0.0.14 which is incompatible.\n",
            "zep-python 1.5.0 requires httpx<0.25.0,>=0.24.0, but you have httpx 0.27.0 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%pip install langgraph langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOSj_MR1AHBs",
        "outputId": "207a3ab4-0503-4b6b-fa24-d630d7cc66a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\richa\\anaconda3\\lib\\site-packages (0.2.0)\n",
            "Requirement already satisfied: langchain_groq in c:\\users\\richa\\anaconda3\\lib\\site-packages (0.1.3)\n",
            "Requirement already satisfied: langchain_community in c:\\users\\richa\\anaconda3\\lib\\site-packages (0.0.38)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (0.6.4)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_core-0.2.40-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (0.1.122)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain_groq) (0.5.0)\n",
            "INFO: pip is looking at multiple versions of langchain-groq to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_groq-0.1.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.3.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\richa\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.11.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.23.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.1)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\richa\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\richa\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Downloading langchain_groq-0.1.10-py3-none-any.whl (14 kB)\n",
            "Downloading langchain_community-0.2.17-py3-none-any.whl (2.3 MB)\n",
            "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "   ------------------------------- -------- 1.8/2.3 MB 11.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.3/2.3 MB 10.2 MB/s eta 0:00:00\n",
            "Downloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
            "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.0/1.0 MB 7.9 MB/s eta 0:00:00\n",
            "Downloading langchain_core-0.2.40-py3-none-any.whl (396 kB)\n",
            "Installing collected packages: langchain-core, langchain_groq, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.1\n",
            "    Uninstalling langchain-core-0.3.1:\n",
            "      Successfully uninstalled langchain-core-0.3.1\n",
            "  Attempting uninstall: langchain_groq\n",
            "    Found existing installation: langchain-groq 0.1.3\n",
            "    Uninstalling langchain-groq-0.1.3:\n",
            "      Successfully uninstalled langchain-groq-0.1.3\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.2.0\n",
            "    Uninstalling langchain-0.2.0:\n",
            "      Successfully uninstalled langchain-0.2.0\n",
            "  Attempting uninstall: langchain_community\n",
            "    Found existing installation: langchain-community 0.0.38\n",
            "    Uninstalling langchain-community-0.0.38:\n",
            "      Successfully uninstalled langchain-community-0.0.38\n",
            "Successfully installed langchain-0.2.16 langchain-core-0.2.40 langchain_community-0.2.17 langchain_groq-0.1.10\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "crewai 0.28.8 requires langchain<0.2.0,>=0.1.10, but you have langchain 0.2.16 which is incompatible.\n",
            "crewai 0.28.8 requires openai<2.0.0,>=1.13.3, but you have openai 0.10.2 which is incompatible.\n",
            "crewai-tools 0.2.3 requires beautifulsoup4<5.0.0,>=4.12.3, but you have beautifulsoup4 4.10.0 which is incompatible.\n",
            "crewai-tools 0.2.3 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.2.16 which is incompatible.\n",
            "crewai-tools 0.2.3 requires openai<2.0.0,>=1.12.0, but you have openai 0.10.2 which is incompatible.\n",
            "crewai-tools 0.2.3 requires requests<3.0.0,>=2.31.0, but you have requests 2.27.1 which is incompatible.\n",
            "embedchain 0.1.102 requires beautifulsoup4<5.0.0,>=4.12.2, but you have beautifulsoup4 4.10.0 which is incompatible.\n",
            "embedchain 0.1.102 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.2.16 which is incompatible.\n",
            "embedchain 0.1.102 requires langchain-openai<0.0.6,>=0.0.5, but you have langchain-openai 0.1.3 which is incompatible.\n",
            "embedchain 0.1.102 requires openai>=1.1.1, but you have openai 0.10.2 which is incompatible.\n",
            "embedchain 0.1.102 requires pypdf<4.0.0,>=3.11.0, but you have pypdf 4.2.0 which is incompatible.\n",
            "langchain-astradb 0.3.0 requires langchain-core<0.2.0,>=0.1.31, but you have langchain-core 0.2.40 which is incompatible.\n",
            "langchain-google-genai 0.0.11 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.2.40 which is incompatible.\n",
            "langchain-google-vertexai 1.0.1 requires langchain-core<0.2.0,>=0.1.42, but you have langchain-core 0.2.40 which is incompatible.\n",
            "langchain-nvidia-ai-endpoints 0.0.9 requires langchain-core<0.2.0,>=0.1.27, but you have langchain-core 0.2.40 which is incompatible.\n",
            "langchain-openai 0.1.3 requires langchain-core<0.2.0,>=0.1.42, but you have langchain-core 0.2.40 which is incompatible.\n",
            "langchain-openai 0.1.3 requires openai<2.0.0,>=1.10.0, but you have openai 0.10.2 which is incompatible.\n",
            "ragstack-ai-langchain 1.0.3 requires langchain==0.1.19, but you have langchain 0.2.16 which is incompatible.\n",
            "ragstack-ai-langchain 1.0.3 requires langchain-community==0.0.38, but you have langchain-community 0.2.17 which is incompatible.\n",
            "ragstack-ai-langchain 1.0.3 requires langchain-core==0.1.52, but you have langchain-core 0.2.40 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain langchain_groq langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgKIrwXJAjgA",
        "outputId": "7eec3700-d2d7-4ca3-bc2c-875c9cae1dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "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\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "groq_api_key=load_dotenv('groq_api_key')\n",
        "langsmith=load_dotenv('LANGSMITH_API_KEY')\n",
        "print(langsmith)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFpKBPoZBQAa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langsmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"CourseLanggraph\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJZl9uX-CFo7"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9vOWf8yCJ4W",
        "outputId": "91931387-650d-4d7a-95de-31735c66ce27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7efbfa765330>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7efbfa764670>, model_name='Gemma2-9b-It', groq_api_key=SecretStr('**********'))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")\n",
        "llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDc7RviFCVKB"
      },
      "source": [
        "## Start Building Chatbot Using Langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPcSBey6CUeF"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph,START,END\n",
        "from langgraph.graph.message import add_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVzn-8rrC6-7"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "  # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "  messages:Annotated[list,add_messages]\n",
        "\n",
        "graph_builder=StateGraph(State)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgjwX6BQDcfk",
        "outputId": "10f24dc5-6242-454b-b61c-cfecf260ae22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7efbfa91fee0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOF74t5GDeJO"
      },
      "outputs": [],
      "source": [
        "def chatbot(state:State):\n",
        "  return {\"messages\":llm.invoke(state['messages'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m7NDe74EPGW"
      },
      "outputs": [],
      "source": [
        "graph_builder.add_node(\"chatbot\",chatbot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKFbmbqcEVIq",
        "outputId": "9f91e0af-022e-4485-8151-db69c5cc3ccb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7efbfa91fee0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jBWX44IEWy-"
      },
      "outputs": [],
      "source": [
        "graph_builder.add_edge(START,\"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\",END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN4O63shEtyZ"
      },
      "outputs": [],
      "source": [
        "graph=graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "_PPER3gfEygm",
        "outputId": "fbe87a93-4e15-47e7-9cc3-5cebe43ce64f"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDvjUFmxFCwU",
        "outputId": "c77c0d85-b6f5-4dee-81c5-5c728019aaed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: hello\n",
            "dict_values([{'messages': AIMessage(content='Hello! 👋  How can I help you today? 😊\\n', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 15, 'total_tokens': 30, 'completion_time': 0.028948375, 'prompt_time': 0.00232277, 'queue_time': None, 'total_time': 0.031271145}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7c991b84-1ff6-461a-baa7-08c8d2767d10-0', usage_metadata={'input_tokens': 15, 'output_tokens': 15, 'total_tokens': 30})}])\n",
            "content='Hello! 👋  How can I help you today? 😊\\n' response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 15, 'total_tokens': 30, 'completion_time': 0.028948375, 'prompt_time': 0.00232277, 'queue_time': None, 'total_time': 0.031271145}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-7c991b84-1ff6-461a-baa7-08c8d2767d10-0' usage_metadata={'input_tokens': 15, 'output_tokens': 15, 'total_tokens': 30}\n",
            "Assistant: Hello! 👋  How can I help you today? 😊\n",
            "\n",
            "User: what is generative ai\n",
            "dict_values([{'messages': AIMessage(content=\"Generative AI is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: instead of simply analyzing existing data, generative AI learns the underlying patterns and structures within that data and then uses that knowledge to generate entirely new outputs.\\n\\nHere's a breakdown:\\n\\n**What it does:**\\n\\n* **Creates new content:** This can include text, images, audio, video, code, and even 3D models.\\n\\n* **Learns from existing data:**  It's trained on massive datasets to understand the nuances and rules of the content it's designed to generate.\\n\\n* **Generates variations:** It can create different variations of a given prompt or input, offering options and exploring creative possibilities.\\n\\n**Examples:**\\n\\n* **Text Generation:**\\n\\nChatGPT (like me!), writing stories, poems, articles, dialogue\\n\\n* **Image Generation:**\\n\\nDALL-E 2, Midjourney creating realistic or imaginative images from text descriptions\\n\\n* **Audio Generation:**\\n\\nJukebox, Amper Music composing music in various styles\\n\\n* **Code Generation:**\\n\\nGitHub Copilot assisting developers in writing code\\n\\n**How it works:**\\n\\nGenerative AI often relies on deep learning algorithms, particularly a type called generative adversarial networks (GANs). These algorithms consist of two neural networks that work in tandem:\\n\\n* **Generator:** Creates new content.\\n* **Discriminator:** Evaluates the quality of the generated content and tries to distinguish it from real data.\\n\\nThrough this competitive process, the generator improves its ability to produce increasingly realistic and sophisticated outputs.\\n\\n**Applications:**\\n\\nGenerative AI has a wide range of potential applications, including:\\n\\n* **Creative Arts:** Writing, music composition, art generation\\n* **Design:** Creating prototypes, generating marketing materials\\n* **Entertainment:** Developing interactive stories, generating game assets\\n* **Research:** Exploring new scientific concepts, simulating experiments\\n* **Education:** Personalized learning experiences, creating interactive learning materials\\n\\n**Ethical Considerations:**\\n\\nWhile generative AI offers exciting possibilities, it also raises ethical concerns:\\n\\n* **Misinformation:** Potential for creating realistic fake news, deepfakes, and propaganda.\\n* **Bias:** AI models can inherit and amplify biases present in the training data, leading to unfair or discriminatory outputs.\\n* **Copyright:** Questions surrounding the ownership and copyright of AI-generated content.\\n\\n\\n\\n\\nLet me know if you have any more questions about generative AI!\\n\", response_metadata={'token_usage': {'completion_tokens': 501, 'prompt_tokens': 18, 'total_tokens': 519, 'completion_time': 1.044149282, 'prompt_time': 0.002699907, 'queue_time': None, 'total_time': 1.046849189}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6b200b57-a482-45f9-a07c-4fa92c425157-0', usage_metadata={'input_tokens': 18, 'output_tokens': 501, 'total_tokens': 519})}])\n",
            "content=\"Generative AI is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: instead of simply analyzing existing data, generative AI learns the underlying patterns and structures within that data and then uses that knowledge to generate entirely new outputs.\\n\\nHere's a breakdown:\\n\\n**What it does:**\\n\\n* **Creates new content:** This can include text, images, audio, video, code, and even 3D models.\\n\\n* **Learns from existing data:**  It's trained on massive datasets to understand the nuances and rules of the content it's designed to generate.\\n\\n* **Generates variations:** It can create different variations of a given prompt or input, offering options and exploring creative possibilities.\\n\\n**Examples:**\\n\\n* **Text Generation:**\\n\\nChatGPT (like me!), writing stories, poems, articles, dialogue\\n\\n* **Image Generation:**\\n\\nDALL-E 2, Midjourney creating realistic or imaginative images from text descriptions\\n\\n* **Audio Generation:**\\n\\nJukebox, Amper Music composing music in various styles\\n\\n* **Code Generation:**\\n\\nGitHub Copilot assisting developers in writing code\\n\\n**How it works:**\\n\\nGenerative AI often relies on deep learning algorithms, particularly a type called generative adversarial networks (GANs). These algorithms consist of two neural networks that work in tandem:\\n\\n* **Generator:** Creates new content.\\n* **Discriminator:** Evaluates the quality of the generated content and tries to distinguish it from real data.\\n\\nThrough this competitive process, the generator improves its ability to produce increasingly realistic and sophisticated outputs.\\n\\n**Applications:**\\n\\nGenerative AI has a wide range of potential applications, including:\\n\\n* **Creative Arts:** Writing, music composition, art generation\\n* **Design:** Creating prototypes, generating marketing materials\\n* **Entertainment:** Developing interactive stories, generating game assets\\n* **Research:** Exploring new scientific concepts, simulating experiments\\n* **Education:** Personalized learning experiences, creating interactive learning materials\\n\\n**Ethical Considerations:**\\n\\nWhile generative AI offers exciting possibilities, it also raises ethical concerns:\\n\\n* **Misinformation:** Potential for creating realistic fake news, deepfakes, and propaganda.\\n* **Bias:** AI models can inherit and amplify biases present in the training data, leading to unfair or discriminatory outputs.\\n* **Copyright:** Questions surrounding the ownership and copyright of AI-generated content.\\n\\n\\n\\n\\nLet me know if you have any more questions about generative AI!\\n\" response_metadata={'token_usage': {'completion_tokens': 501, 'prompt_tokens': 18, 'total_tokens': 519, 'completion_time': 1.044149282, 'prompt_time': 0.002699907, 'queue_time': None, 'total_time': 1.046849189}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-6b200b57-a482-45f9-a07c-4fa92c425157-0' usage_metadata={'input_tokens': 18, 'output_tokens': 501, 'total_tokens': 519}\n",
            "Assistant: Generative AI is a type of artificial intelligence that focuses on creating new content. \n",
            "\n",
            "Think of it like this: instead of simply analyzing existing data, generative AI learns the underlying patterns and structures within that data and then uses that knowledge to generate entirely new outputs.\n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "**What it does:**\n",
            "\n",
            "* **Creates new content:** This can include text, images, audio, video, code, and even 3D models.\n",
            "\n",
            "* **Learns from existing data:**  It's trained on massive datasets to understand the nuances and rules of the content it's designed to generate.\n",
            "\n",
            "* **Generates variations:** It can create different variations of a given prompt or input, offering options and exploring creative possibilities.\n",
            "\n",
            "**Examples:**\n",
            "\n",
            "* **Text Generation:**\n",
            "\n",
            "ChatGPT (like me!), writing stories, poems, articles, dialogue\n",
            "\n",
            "* **Image Generation:**\n",
            "\n",
            "DALL-E 2, Midjourney creating realistic or imaginative images from text descriptions\n",
            "\n",
            "* **Audio Generation:**\n",
            "\n",
            "Jukebox, Amper Music composing music in various styles\n",
            "\n",
            "* **Code Generation:**\n",
            "\n",
            "GitHub Copilot assisting developers in writing code\n",
            "\n",
            "**How it works:**\n",
            "\n",
            "Generative AI often relies on deep learning algorithms, particularly a type called generative adversarial networks (GANs). These algorithms consist of two neural networks that work in tandem:\n",
            "\n",
            "* **Generator:** Creates new content.\n",
            "* **Discriminator:** Evaluates the quality of the generated content and tries to distinguish it from real data.\n",
            "\n",
            "Through this competitive process, the generator improves its ability to produce increasingly realistic and sophisticated outputs.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "Generative AI has a wide range of potential applications, including:\n",
            "\n",
            "* **Creative Arts:** Writing, music composition, art generation\n",
            "* **Design:** Creating prototypes, generating marketing materials\n",
            "* **Entertainment:** Developing interactive stories, generating game assets\n",
            "* **Research:** Exploring new scientific concepts, simulating experiments\n",
            "* **Education:** Personalized learning experiences, creating interactive learning materials\n",
            "\n",
            "**Ethical Considerations:**\n",
            "\n",
            "While generative AI offers exciting possibilities, it also raises ethical concerns:\n",
            "\n",
            "* **Misinformation:** Potential for creating realistic fake news, deepfakes, and propaganda.\n",
            "* **Bias:** AI models can inherit and amplify biases present in the training data, leading to unfair or discriminatory outputs.\n",
            "* **Copyright:** Questions surrounding the ownership and copyright of AI-generated content.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Let me know if you have any more questions about generative AI!\n",
            "\n",
            "User: q\n",
            "Good Bye\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  user_input=input(\"User: \")\n",
        "  if user_input.lower() in [\"quit\",\"q\"]:\n",
        "    print(\"Good Bye\")\n",
        "    break\n",
        "  for event in graph.stream({'messages':(\"user\",user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['messages'])\n",
        "      print(\"Assistant:\",value[\"messages\"].content)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
